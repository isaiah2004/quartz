#llms #AI #GenAi #Testing

[MTEB: Massive Text Embedding Benchmark (huggingface.co)](https://huggingface.co/blog/mteb)

# MTEB: Massive Text Embedding Benchmark 

"MTEB is a massive benchmark for measuring the performance of text embedding models on diverse embedding tasks."

The ğŸ¥‡Â [leaderboard](https://huggingface.co/spaces/mteb/leaderboard)Â provides a holistic view of the best text embedding models out there on a variety of tasks.

The ğŸ“Â [paper](https://arxiv.org/abs/2210.07316)Â gives background on the tasks and datasets in MTEB and analyzes leaderboard results!

The ğŸ’»Â [Github repo](https://github.com/embeddings-benchmark/mteb)Â contains the code for benchmarking and submitting any model of your choice to the leaderboard.

## Benchmark your model

Using theÂ [MTEB library](https://github.com/embeddings-benchmark/mteb), you can benchmark any model that produces embeddings and add its results to the public leaderboard.

