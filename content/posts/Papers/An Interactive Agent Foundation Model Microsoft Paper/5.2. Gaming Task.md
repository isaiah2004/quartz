Primary Dataset was Minecraft demonstrations dataset by contractors in the below paper.
[[2206.11795] Video PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos (arxiv.org)](https://arxiv.org/abs/2206.11795)

"In the original dataset, contractors were simply in structed to play Minecraft with no specific goal, and the dataset provided video gameplay synchronized with player actions and inventory metadata."

Using GPT-4V they label the videos with more specific examples.

They also prompt GPT-4V with the inventory and metadata to achieve a higher accuracy.

Total no of frames: 4.7 million frames


They also used a dataset from game called Bleeding edge. Consisting of video and syncrnised player actions. They used GPT-4V to label this data too. 

They gathered data across & different settings in game 

Total no of frames: 2.3 million frames 


> [!NEXT] NEXT 
> [[5.3 Healthcare Task]]



