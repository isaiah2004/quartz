
## We evaluated the performance of a large language model, ChatGPT, on the United States Medical Licensing Exam (USMLE).
- The USMLE comprises three exams:
    - Step 1
    - Step 2CK
    - Step 3
- ChatGPT performed at or near the passing threshold for all three exams without any specialized training or reinforcement.
- Additionally, ChatGPT demonstrated a high level of concordance and insight in its explanations.
- These results suggest that large language models may have the potential to assist with medical education and potentially, clinical decision-making.


## Author  summary summary

- Artificial intelligence (AI) systems show potential to improve medical care and health outcomes, highlighting the importance of trust and explainability in their development.
- Evaluating AI's medical knowledge against that of human experts is essential for assessing these qualities.
- We assessed ChatGPT on the USMLE, a series of three exams required for medical licensure in the United States, finding it performed at or near the 60% passing threshold.
- This achievement, without specialized human input, marks a significant milestone in AI development.
- ChatGPT's ability to provide comprehensible reasoning and valid clinical insights reinforces trust and explainability.
- The study indicates that large language models like ChatGPT could support medical education and possibly contribute to future clinical decision-making.

